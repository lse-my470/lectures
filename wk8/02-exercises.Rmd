---
title: "MY470: Class exercises week 8"
author: "Friedrich Geiecke"
date: "16/11/2020"
output: html_document
---

In this document we will study vectorised code and the substantial speedups it can achieve in some applications. We will also study the effect on speed when code creates new copies that are not necessary. Both topics are very helpful to know about, not just in R, but in programming more generally (you will find very similar results e.g. with numpy). For example, today's work and research with neural networks relies heavily on using optimised vectorised computations as these models can have arrays with millions of parameters. Similarly, iterating through every element in a network (e.g. studying some social network data) with a loop in R will be much slower than computing the same outcomes in a vectorised way with element-wise computations or matrix products that use pre-optimised code. Lastly, knowing that loops are slower when they create copies of objects where this is not necessary, can speed up a range of use cases also in every day work as a data scientist.

1. Let us first think about memory addresses of objects. This sounds fairly abstract, but can quickly have consequences for the speed of code that is executed repeatedly. R copies a wide range of objects to a new location in memory when they are modified. Yet, if a vector is only assigned to a single name (i.e. `x <- c(1,2,3)` and **nothing like** `y<-x`), R actually modifies `x` in place. Let us look at an example using the `address` function from the package `pryr` which checks the location of objects in memory. Before you can load `pryr` with `library("pryr")`, you have to once install it *only once* with `install.packages("pryr")`. The goal is simply to use a for loop to compute a vector called `vector_of_squares` which contains the squared elements of a vector `x`. We will do this in two ways (of course we could also just use a vectorised operation and we will do this later). Option 1 first creates an empty output vector with correct final length and then fills it with a loop. Option 2 appends each new element to a vector with the `append()` function implicitly forcing R to create a copy of the object at each iteration of the loop. Both would yield an identical output vector, however, have important differences in term of memory allocation. Fix the code below such that it can run. What do you find?

```{r}

# This code creates a vector `vector_of_squares` which contains the squared
# elements of the vector x

# Loading the relevant package to use the `address()` function
library(____)

# Creating an exemplary vector with 10 elements
x <- ____

# Creating an empty vector with correct final length
vector_of_squares <- numeric(length(x))
  
for (i in 1:length(x)) {
  
  # Replacing the relevant element of the empty vector with the associated square
  vector_of_squares[i] <- x[i]*x[____]
  
  # Printing out the memory address of the vector
  print(address(vector_of_squares))
}

vector_of_squares
```

```{r}

# This code also creates a vector `vector_of_squares` which contains the squared
# elements of the vector x

# Creating an empty vector with length zero
vector_of_squares <- numeric(0)

for (i in 1:length(x)) {
  
  # Appending every new element to the vector which implicitly creates a copy
  vector_of_squares <- append(____, x[i]*x[____])
  
  # Printing out the memory address of the vector
  print(address(vector_of_squares))
}

vector_of_squares
```

2. The length of an (Euclidean) vector x = (x1, x2, x3, ...) in linear algebra is given by ||x|| = sqrt(x1^2 + x2^2 + x3^2 + ...), i.e. a generalisation of the Pythagorean theorem - think of a vector of 2 elements. This means that if we sum up the elements in our `vector_of_squares` computed before and then take the square root, i.e. sqrt(sum(vector_of_squares)), we have already computed the length of x! Let us write five functions which can all compute the length of a vector x. One uses a for loop with a mutable vector, one uses a for loop which implicitly creates new copies of the vector in each step, one uses an apply function, and two use vectorised operations only. Fix the code in each of the functions below such that it can run.

Hint 1: If you need a function only once, it is common to use [anonymous function](http://adv-r.had.co.nz/Functional-programming.html#anonymous-functions). Concepts similar to anonymous functions are used for many single use tasks in functional programming styles. For example, the following two options will achieve the same thing, but one is less work to write down. You can adapt this logic to compute x_i*x_i for each element of a vector x with the `sapply` function.

```{r}
some_vector <- c(1,2,5)
my_function <- function(x) {
  x + 5
}
# `sapply` applies a function to every element of a vector
sapply(some_vector, my_function)
```

```{r}
vector_of_squares <- c(1,2,5)
# The anonymous function works as well and does not require you to define a
# separate function
sapply(some_vector, function(y) y + 5)
```

Hint 2: No need to think too much about the concept of a vector length and the mathematics here. The key of this exercise is the following: We will compute an identical outcome in different ways, with loops (one loop being smart and not creating new copies and the other loop being less smart), with apply, and with vectorised code. This allows us to compare the speed of different approaches. The vector length is just an application.

```{r}


vector_length_a <- function(x) {

  #
  # This function computes the vector length with a loop, modifying the
  # vector in the same memory location
  #
  
  # Creating an empty vector with correct final length
  vector_of_squares <- numeric(length(____))
  
  # Filling out the vector
  for (i in 1:length(x)) {
    
    vector_of_squares[i] <- x[i]*x[i]
    
  }
  
  # Obtaining the dot product
  dot_product <- sum(____)
  
  # Obtaining the final vector length
  vector_length <- sqrt(____)
  
  return(vector_length)
  
}


vector_length_b <- function(x) {

  #
  # This function computes the vector length with a loop, however, the
  # code creates copies of the vector implicitly
  #
  
  # Creating an empty vector of length zero
  vector_of_squares <- numeric(0)
  
  # Filling out the vector
  for (i in 1:length(x)) {
    
    ____ <- append(____, x[i]*x[i])
    
  }
  
  # Obtaining the dot product
  dot_product <- sum(____)
  
  # Obtaining the final vector length
  vector_length <- sqrt(____)
  
  return(vector_length)
  
}
  

  
vector_length_c <- function(x) {
  
  #
  # This function uses an apply approach to avoid writing the for loop
  # explicitly
  #
  
  # Using sapply and an anonymous function to compute the vector of squares
  vector_of_squares <- sapply(x, ____)
  
  # Obtaining the dot product
  dot_product <- sum(____)
  
  # Obtaining the final vector length
  vector_length <- sqrt(____)
  
  return(vector_length)

}

vector_length_d <- function(x) {
  
  #
  # This function uses the operator for matrix multiplication in R
  #
  
  dot_product <- x____x
  vector_length <- sqrt(dot_product[1,1])
  
  return(vector_length)

}

vector_length_e <- function(x) {
  
  #
  # This function uses element wise multiplication
  #
  
  dot_product <- sum(x____x)
  vector_length <- sqrt(dot_product)
  
  return(vector_length)

}

```

Check whether all functions return the same outcome:

```{r}

some_example_vector <- ____

vector_length_a(some_example_vector)
vector_length_b(some_example_vector)
vector_length_c(some_example_vector)
vector_length_d(some_example_vector)
vector_length_e(some_example_vector)
```


3. Now you can use all of these functions to compute the length of an Euclidean vector. Let us evaluate, however, how long each function takes to achieve the same outcome. In such considerations, it is advisable to evaluate each cell for multiple times, e.g. 10 or more (also depending on the speed of your computer), to have more reliable estimates of the user time which might vary from run to run. We will use the `system.time` function which achieves just that. Which of the five functions is the fastest, i.e. has the lowest user time? What are the relative differences in speed between the different approaches, how many times is one version faster than another?


```{r}
# Some arbitrary vector with 10000 elements of which we will determine the length
x <- 42:10041

# Number of repetitions when timing the code (time in individual repetitions
# fluctuates a lot. Increase the value of n if you have a fast computer)
n <- 10
```

Computing the outcome with a loop that modifies the vector in the same memory location:

```{r}
system.time(for (i in 1:n) vector_length_a(x))
```

Computing the outcome with a loop that implicitly creates a copy of the vector in each iteration:

```{r}
system.time(for (i in 1:n) vector_length_b(x))
```

Computing the outcome with an `sapply` function:

```{r}
system.time(for (i in 1:n) vector_length_c(x))
```

Computing the outcome with vectorised code and a dot product:

```{r}
system.time(for (i in 1:n) vector_length_d(x))
```

Computing the outcome with element-wise multiplication:

```{r}
system.time(for (i in 1:n) vector_length_e(x))
```

With our vector length being only a simple example, these considerations are also relevant for every day work as a developer or data scientist. Imagine for example, you need to clean some texts contained in a column of a big real world dataset with millions of rows. To loop over all rows of the dataset and to clean the texts contained in that column for each row would conceptually be the same as our example here: We looped over all rows of a vector and computed the square of each element (computing the square is just a different computation than cleaning text stored elements of a column vector). It might not be possible to find a vectorised approach in such cases that can be applied to the entire column vector of texts in one go, so a loop or apply function could become necessary. Yet, knowing about the issues with implicit object copies can often explain why code in such cases is unnecessarily slow.
